import pandas as pd


info={
    "Name":["Ravi Panchal","Anurag Jaiswal","Abhinav Kesarwani","Ajitesh Channa"],
    "CGPA":[8.44,8.12,9.67,9.35],
}

df=pd.DataFrame(info)
print(df)


df


#Series
s=pd.Series([1,2,3,4,5])
print(s)
print(type(s))

print(s[0]) #1
print(s[3]) #4



s=pd.Series([30,22,34,12],index=["Ravi","Anurag","Vivek","Rishav"])
print(s)
print(s["Ravi"])
print(s.index)


s1=pd.Series([1,2,3,4,5])
s2=pd.Series([6,7,8,9,10])
s3=s1+s2
print(s3)
s3[0]=100
print(s3)


#DataFrame
info={
    "Name":["Ravi","Rishav","Abhinav","Prabhat"],
    "age":[21,23,22,25],
    "CGPA":[7,8,9.6,9] 
}

df=pd.DataFrame(info)

print(df, type(df))


df


#list of list
df=pd.DataFrame([["Ravi",22],["Abhinav",24],["Ajitesh",31]],columns=["Name","Age"])
print(df)


df


import numpy as np
np_arr=np.array([[1,2,3,4],[5,6,7,8]])
df=pd.DataFrame(np_arr, columns=["A","B","C","D"])

df


#csv data
df=pd.read_csv("employee_data.csv")
print(df, type(df))


#json data
df=pd.read_json("employee_data.json")
print(df, type(df))


#AQI dataset
import pandas as pd
df=pd.read_csv("globalAirQuality.csv")
# df.head()
# df.tail()
# df.describe()
# df.sample()
# df.info()
# df.nunique()


#air quality data
df=pd.read_csv("globalAirQuality.csv")
# df.describe()


df



df[["city","aqi"]]
df.loc[0]
df.loc[0:2] #start idx->end idx(inclusive)



df.iloc[0]
df.iloc[0:2] #start idx->end idx(Not inclusive)


df.loc[0:2, ["city","country","latitude","longitude"]]


df.columns


df.iloc[0:2,[1,2,3,4]]


# df.at[0,"city"]
df[df["aqi"]>100]


df[(df["aqi"]>100) & (df["temperature"]>30)]


df[df["aqi"]>100][["city","country"]]


#filtering of data
aqi_data=df[(df["aqi"]>100) & (df["temperature"]>30)] [["city","country"]]
aqi_data
# aqi_data.iloc[0]
aqi_data.loc[6]




#Query method
df.query("aqi>100 and temperature>30")[["city","country"]]


#read the data
df=pd.read_csv("raw_data.csv")
df


df.isnull()
df.isna()


df.isnull().sum()


df.dropna()


df.dropna(axis=1) #delete all coulumns who contains null values


df.fillna(0)



cleaned_data=df.copy()
age_mean=cleaned_data["age"].mean()
cleaned_data["age"]=df["age"].fillna(age_mean)
cleaned_data


df.ffill()  #forward fill the data, basicall just upar wali value ko neeche copy paste kar dete hai


df.bfill() #backward


#Handle duplicate
df["country"].duplicated()


df.drop_duplicates()


#Data types
df.dtypes


date_str=pd.Series([pd.to_datetime("08-01-2026")])
type(date_str.dtypes)



#Handle String
df["name"].str.upper()
df["name"].str.split(" ")
df["country"].str.contains("India",case=False)


df


#Feature Engineering
df2=df.copy()
df2["tax"]=df2["income"].apply(lambda x: "20%" if x<60000 else "10%")

gender_map={"Female":"F","Male":"M","Unknown":"U"}
df2["gender"]=df2["gender"].map(gender_map)

df2.assign(new_income=df2["income"] * 1.1)

df2["country"]=df2["country"].replace("USA","United States")

df2.columns=["Id","Name","Age","Country","Gender","Income","Tax"]

df2.rename(columns={"Income":"Salary"})
df2.rename(index={3:"Alex"})

#sort the values
df2.sort_values("Income")
# df2=df2.fillna(50)
# df2.sort_values("Income",ascending=False)
# df2.sort_index()

#Ranking
df2["Ranking"]=df2["Income"].rank()

df2


#shift the column towards end
df1=df.copy()
new_col_order=[col for col in df1.columns if col!="id"]+["id"]
print(new_col_order)
df1[new_col_order]


#Writing in the csv data
df3=df.copy()
df3=df3.drop_duplicates()
df3=df3.fillna(0)
df3=df3.sort_values("income")
df3=df3.reset_index(drop=True)

#save the sorted data
df3.to_csv("sorted_data.csv")


df


#Grouping and Aggregation of data
df.groupby("country")["income"].mean()
df.groupby("country")["income"].max()
df.groupby("country")["income"].min()


df.groupby("gender")["income"].mean()

#aggreagate
df.groupby("gender")["income"].agg(["min","max","mean"])
df.groupby("gender")["income"].agg(min_salary="min",max_salary="max",mean_salary="mean") #rename 


df.groupby("country").agg({
    "income":"mean",
    "age":"mean"
})

df.groupby("country").agg(
    min_salary=("income","min"),
    mean_age=("age","mean")
)


df=pd.DataFrame({
    "country":["USA","USA","India","India"],
    "year":[2020,2021,2020,2021],
    "sales":[100,120,90,110],
    "profit":[20,25,18,22],
    # "tax":[10,20,30,40]
})

melted_df=df.melt(
    id_vars=["country","year"],
    value_vars=["sales","profit"],
    var_name="metrics",
    value_name="value"
)


original=melted_df.pivot(
    index=["country","year"],
    columns="metrics",
    values="value"
)


original


#Basic Visualization
df=pd.read_csv("employee_data.csv")

df["Age"].hist()


df.plot(kind="scatter",x="Age",y="Salary")


#merging and joing the data
df_customers=pd.DataFrame({
    "customer_id":[1,2,3,4],
    "name":["Adam","Bob","Charlie","Dave"]
})

df_orders=pd.DataFrame({
    "order_id":[101,102,103,104],
    "customer_id":[2,1,4,5],
    "amount":[250,120,300,180]
})


df_customers


df_orders


pd.merge(df_customers,df_orders,on="customer_id") #Inner Join
pd.merge(df_customers,df_orders,on="customer_id",how="left") #left Join
pd.merge(df_customers,df_orders,on="customer_id",how="right") #right Join
pd.merge(df_customers,df_orders,on="customer_id",how="outer") #outer Join



#concatenation
df1=pd.DataFrame({
    "id":[1,2,3],
    "name":["Ravi","Rishav","Anurag"]
})

df2=pd.DataFrame({
    "id":[4,5,6],
    "name":["Abhinav","Ajitesh","Gagan"]
})

pd.concat([df1,df2])  #row wise
pd.concat([df1,df2],ignore_index=True)  #assign new label
pd.concat([df1,df2], axis=1)  #col wise



